% ---------- chapters/introduction.tex ----------
\chapter{Introduction}\label{ch:intro}

\section{Motivation}

Two mainstream routes for improving reasoning in language models are

\begin{enumerate}
    \item \textbf{Scaling the network} by adding more layers or wider
          matrices.
    \item \textbf{Embedding chain‑of‑thought (CoT) prompts} so the model
          spells out each intermediate step.
\end{enumerate}

Both approaches increase runtime demands: parameters grow quadratically
with width, and CoT inflates the prompt length linearly with reasoning
depth.

A lighter alternative is to keep parameters and prompt length fixed while
giving the model \emph{more time}—looping a shared block over its own hidden
state.  This project explores that idea in a resource‑constrained setting
(single consumer GPU, $<$100 M parameters) and asks:

\begin{itemize}
    \item Can hidden‑state recurrence improve a compact model?
    \item How does latent recurrence compare with a token‑level loop under
          identical training recipes?
\end{itemize}

We re‑implement both variants from scratch, fine‑tune them on a
math‑reasoning corpus, and analyse loss curves and qualitative behaviour.

